{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "746ab4fc-154f-42cd-a48d-6798751da67b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib_venn import venn3, venn2\n",
    "import matplotlib.pyplot as plt\n",
    "import ot\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from scipy.stats import ranksums\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import time\n",
    "\n",
    "from pydeseq2.dds import DeseqDataSet\n",
    "from pydeseq2.ds import DeseqStats\n",
    "import scvi\n",
    "from statsmodels.discrete.count_model import ZeroInflatedNegativeBinomialP\n",
    "\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0cc1d4f9-15f2-4786-8020-3ac180295503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "\n",
    "def filter_genes_expressed_in_both_groups(\n",
    "    adata: ad.AnnData,\n",
    "    group_column: str,\n",
    "    group1: str,\n",
    "    group2: str,\n",
    "    threshold: int = 5\n",
    ") -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    Filters genes in an AnnData object to keep only those expressed in both specified groups.\n",
    "\n",
    "    Parameters:\n",
    "    - adata (AnnData): The input AnnData object.\n",
    "    - group_column (str): Column name in `.obs` that contains group labels.\n",
    "    - group1 (str): Name of the first group (e.g., 'aHD').\n",
    "    - group2 (str): Name of the second group (e.g., 'aSLE').\n",
    "    - threshold (int): Minimum number of cells a gene must be expressed in (>0) to be considered expressed.\n",
    "\n",
    "    Returns:\n",
    "    - AnnData: A new AnnData object filtered to keep only genes expressed in both groups.\n",
    "    \"\"\"\n",
    "    # Create masks for each group\n",
    "    group1_mask = np.sum(adata[adata.obs[group_column] == group1].X > 0, axis=0) > threshold\n",
    "    group2_mask = np.sum(adata[adata.obs[group_column] == group2].X > 0, axis=0) > threshold\n",
    "\n",
    "    # Find genes expressed in both groups\n",
    "    expressed_in_both = np.array(group1_mask).ravel() & np.array(group2_mask).ravel()\n",
    "\n",
    "    # Return filtered AnnData object\n",
    "    return adata[:, expressed_in_both].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e304099d-782b-4c56-8dab-26f72fde0381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "\n",
    "def extract_group_expression(\n",
    "    adata: ad.AnnData,\n",
    "    group_column: str,\n",
    "    group_labels: list\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts gene expression data for specified groups and returns a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - adata (AnnData): Filtered AnnData object.\n",
    "    - group_column (str): Column in `.obs` that contains group labels.\n",
    "    - group_labels (list): List of group names to include (e.g., ['cHD', 'aHD']).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Gene expression matrix with genes as columns.\n",
    "    \"\"\"\n",
    "    group_data = adata[adata.obs[group_column].isin(group_labels)]\n",
    "    genes = adata.var_names\n",
    "\n",
    "    # Convert sparse matrix to dense if needed\n",
    "    if hasattr(group_data.X, \"toarray\"):\n",
    "        expression = group_data.X.toarray()\n",
    "    else:\n",
    "        expression = group_data.X\n",
    "\n",
    "    return pd.DataFrame(expression, columns=genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7162c835-235b-43c2-bc10-9cee1f4fc807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def perform_pca(\n",
    "    expression_df: pd.DataFrame,\n",
    "    n_components: int = 15\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs PCA on the expression DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - expression_df (pd.DataFrame): Gene expression matrix.\n",
    "    - n_components (int): Number of PCA components to compute.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Transformed PCA components.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pcs = pca.fit_transform(expression_df)\n",
    "    return pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64cd82b5-aaa5-4b93-91ea-c869bba5419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "import numpy as np\n",
    "\n",
    "def fit_kde(pcs: np.ndarray, bw_method: str = 'scott') -> gaussian_kde:\n",
    "    \"\"\"\n",
    "    Fits a Gaussian KDE to the input principal components.\n",
    "\n",
    "    Parameters:\n",
    "    - pcs (np.ndarray): PCA-transformed data (rows = samples, cols = components).\n",
    "    - bw_method (str): Bandwidth estimation method (default: 'scott').\n",
    "\n",
    "    Returns:\n",
    "    - gaussian_kde: Fitted KDE object.\n",
    "    \"\"\"\n",
    "    return gaussian_kde(pcs.T, bw_method=bw_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1daf6839-5307-45d8-822e-303f653876d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_density(kde_model: gaussian_kde, pcs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Evaluates density values for the input PCA data using a fitted KDE model.\n",
    "\n",
    "    Parameters:\n",
    "    - kde_model (gaussian_kde): Fitted KDE model.\n",
    "    - pcs (np.ndarray): PCA-transformed data.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Density estimates.\n",
    "    \"\"\"\n",
    "    return kde_model(pcs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "881387bc-2244-4a90-982a-133f43a499b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_density(density: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes a density array using min-max scaling to [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "    - density (np.ndarray): Raw density values.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Normalized density values (between 0 and 1).\n",
    "    \"\"\"\n",
    "    min_val = np.min(density)\n",
    "    max_val = np.max(density)\n",
    "    if max_val - min_val == 0:\n",
    "        return np.zeros_like(density)\n",
    "    return (density - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8d4c9b1-4e29-4f07-85da-8b74827e5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot  # POT: Python Optimal Transport\n",
    "\n",
    "def compute_cost_matrix(\n",
    "    X1: np.ndarray,\n",
    "    X2: np.ndarray,\n",
    "    metric: str = 'euclidean'\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the cost matrix (pairwise distances) between two sets of samples.\n",
    "\n",
    "    Parameters:\n",
    "    - X1 (np.ndarray): Samples from group 1 (shape: [n_samples_1, n_features]).\n",
    "    - X2 (np.ndarray): Samples from group 2 (shape: [n_samples_2, n_features]).\n",
    "    - metric (str): Distance metric to use (default: 'euclidean').\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Cost matrix of shape [n_samples_1, n_samples_2].\n",
    "    \"\"\"\n",
    "    return ot.dist(X1, X2, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a0a5e6f-31ff-4266-9132-adb0c8bf7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cost_matrix(cost_matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes a cost matrix using min-max scaling to [0, 1].\n",
    "\n",
    "    Parameters:\n",
    "    - cost_matrix (np.ndarray): Raw cost matrix.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Normalized cost matrix.\n",
    "    \"\"\"\n",
    "    min_val = np.min(cost_matrix)\n",
    "    max_val = np.max(cost_matrix)\n",
    "    if max_val - min_val == 0:\n",
    "        return np.zeros_like(cost_matrix)\n",
    "    return (cost_matrix - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1f8e2099-9f67-472e-a2f8-1362625c1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot\n",
    "\n",
    "def compute_transport_plan(\n",
    "    mu: np.ndarray,\n",
    "    nu: np.ndarray,\n",
    "    cost_matrix: np.ndarray,\n",
    "    reg: float = 1.0\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the optimal transport plan using the Sinkhorn algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - mu (np.ndarray): Source distribution (must sum to 1).\n",
    "    - nu (np.ndarray): Target distribution (must sum to 1).\n",
    "    - cost_matrix (np.ndarray): Normalized cost matrix (shape: [n, m]).\n",
    "    - reg (float): Regularization parameter (lambda).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Optimal transport plan (same shape as cost_matrix).\n",
    "    \"\"\"\n",
    "\n",
    "    # Run Sinkhorn algorithm\n",
    "    transport_plan = ot.sinkhorn(mu, nu, cost_matrix, reg)\n",
    "    return transport_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff7e8c95-da7a-47b3-9846-a59198c825de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_expression_difference(\n",
    "    transport_plan: np.ndarray,\n",
    "    source_expression: np.ndarray,\n",
    "    target_expression: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes gene expression differences between original and transported profiles.\n",
    "\n",
    "    Parameters:\n",
    "    - transport_plan (np.ndarray): Optimal transport plan (shape: [n_source, n_target]).\n",
    "    - source_expression (np.ndarray): Expression matrix for source group (Group 0), shape [n_source, n_genes].\n",
    "    - target_expression (np.ndarray): Expression matrix for target group (Group 1), shape [n_target, n_genes].\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Expression difference matrix, shape [n_source, n_genes].\n",
    "    \"\"\"\n",
    "    # Normalize transport plan row-wise\n",
    "    row_sums = transport_plan.sum(axis=1, keepdims=True)\n",
    "    row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "    transport_plan_normalized = transport_plan / row_sums\n",
    "\n",
    "    # Compute transported expression profiles\n",
    "    transported_expr = np.dot(transport_plan_normalized, target_expression)\n",
    "\n",
    "    # Compute expression difference\n",
    "    expr_difference = transported_expr - source_expression\n",
    "\n",
    "    return expr_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e7a99c94-c5d8-4bae-a28b-aa55b305b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_standard_error(\n",
    "    expr_diff: np.ndarray,\n",
    "    ddof: int = 1\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the standard error of expression differences for each gene.\n",
    "\n",
    "    Parameters:\n",
    "    - expr_diff (np.ndarray): Expression difference matrix [n_cells, n_genes].\n",
    "    - ddof (int): Delta degrees of freedom for std calculation (default = 1).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Adjusted standard error for each gene (shape: [n_genes]).\n",
    "    \"\"\"\n",
    "    n_cells = expr_diff.shape[0]\n",
    "    \n",
    "    # Compute standard deviation across cells (per gene)\n",
    "    std_diff = np.std(expr_diff, axis=0, ddof=ddof)\n",
    "    \n",
    "    # Compute standard error\n",
    "    se_diff = std_diff / np.sqrt(n_cells)\n",
    "    \n",
    "    # Adjust to avoid division by zero\n",
    "    se_diff_adj = np.where(se_diff == 0, np.finfo(float).eps, se_diff)\n",
    "\n",
    "    return se_diff_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a0f41c75-f97a-41a0-a557-ec06f5f245f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "def perform_wald_test(\n",
    "    expr_diff: np.ndarray,\n",
    "    se_diff_adj: np.ndarray\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Performs Wald test on gene expression differences and applies FDR correction.\n",
    "\n",
    "    Parameters:\n",
    "    - expr_diff (np.ndarray): Expression difference matrix [n_cells, n_genes].\n",
    "    - se_diff_adj (np.ndarray): Adjusted standard errors [n_genes].\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary with keys:\n",
    "        - 'mean_diff': Mean expression difference per gene\n",
    "        - 'wald_stat': Wald statistics per gene\n",
    "        - 'p_values': Two-tailed p-values\n",
    "        - 'adj_p_values': FDR-adjusted p-values (Benjamini-Hochberg)\n",
    "    \"\"\"\n",
    "    # Compute mean difference\n",
    "    mean_diff = np.mean(expr_diff, axis=0)\n",
    "\n",
    "    # Compute Wald statistics\n",
    "    wald_stat = mean_diff / se_diff_adj\n",
    "\n",
    "    # Compute two-tailed p-values\n",
    "    p_values = 2 * norm.sf(np.abs(wald_stat))\n",
    "\n",
    "    # Adjust p-values using Benjamini-Hochberg FDR\n",
    "    _, adj_p_values, _, _ = multipletests(p_values, method='fdr_bh')\n",
    "\n",
    "    return {\n",
    "        \"mean_diff\": mean_diff,\n",
    "        \"wald_stat\": wald_stat,\n",
    "        \"p_values\": p_values,\n",
    "        \"adj_p_values\": adj_p_values\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c083b5be-4c8d-40fb-ad79-ffbfa94b3c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_pvalue_histogram(\n",
    "    p_values: np.ndarray,\n",
    "    bins: int = 50,\n",
    "    title: str = \"Histogram of P-Values under Null Hypothesis\",\n",
    "    figsize: tuple = (8, 6),\n",
    "    color: str = 'skyblue'\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a histogram of p-values.\n",
    "\n",
    "    Parameters:\n",
    "    - p_values (np.ndarray): Array of p-values.\n",
    "    - bins (int): Number of bins in the histogram (default: 50).\n",
    "    - title (str): Plot title.\n",
    "    - figsize (tuple): Size of the figure.\n",
    "    - color (str): Bar color for the histogram.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.hist(p_values, bins=bins, color=color, edgecolor='black')\n",
    "    plt.xlabel('P-Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b505a79f-d16e-4c82-a7a1-1ebc64a33bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_gene_density_comparison(\n",
    "    df_hd: pd.DataFrame,\n",
    "    df_sle: pd.DataFrame,\n",
    "    genes,\n",
    "    group_labels: tuple = (\"HD\", \"SLE\"),\n",
    "    figsize: tuple = (10, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots KDE for one or more genes in both HD and SLE groups.\n",
    "\n",
    "    Parameters:\n",
    "    - df_hd (pd.DataFrame): Expression data for HD group.\n",
    "    - df_sle (pd.DataFrame): Expression data for SLE group.\n",
    "    - genes (str or list): One gene or list of genes to plot.\n",
    "    - group_labels (tuple): Labels for the HD and SLE groups.\n",
    "    - figsize (tuple): Size of each subplot.\n",
    "    \"\"\"\n",
    "    if isinstance(genes, str):\n",
    "        genes = [genes]  # Wrap single gene name in a list\n",
    "\n",
    "    for gene in genes:\n",
    "        if gene not in df_hd.columns or gene not in df_sle.columns:\n",
    "            raise ValueError(f\"Gene '{gene}' not found in one of the DataFrames.\")\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.kdeplot(df_hd[gene], fill=True, label=group_labels[0], color='skyblue', linewidth=2)\n",
    "        sns.kdeplot(df_sle[gene], fill=True, label=group_labels[1], color='salmon', linewidth=2)\n",
    "\n",
    "        plt.xlabel('Expression Level')\n",
    "        plt.ylabel('Density')\n",
    "        plt.title(f\"Density Comparison for Gene: {gene}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.4)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6ca49254-cd83-4643-8c44-6e3302f11711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_gene_violin_comparison(\n",
    "    df_hd: pd.DataFrame,\n",
    "    df_sle: pd.DataFrame,\n",
    "    genes,\n",
    "    group_labels: tuple = (\"HD\", \"SLE\"),\n",
    "    figsize: tuple = (8, 6)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots violin plots for one or more genes comparing HD vs SLE.\n",
    "\n",
    "    Parameters:\n",
    "    - df_hd (pd.DataFrame): Expression data for HD group.\n",
    "    - df_sle (pd.DataFrame): Expression data for SLE group.\n",
    "    - genes (str or list): One gene or list of genes to plot.\n",
    "    - group_labels (tuple): Labels for HD and SLE groups.\n",
    "    - figsize (tuple): Size of each individual figure.\n",
    "    \"\"\"\n",
    "    if isinstance(genes, str):\n",
    "        genes = [genes]\n",
    "\n",
    "    for gene in genes:\n",
    "        if gene not in df_hd.columns or gene not in df_sle.columns:\n",
    "            raise ValueError(f\"Gene '{gene}' not found in one of the DataFrames.\")\n",
    "\n",
    "        # Combine data\n",
    "        df_plot = pd.DataFrame({\n",
    "            \"Expression\": pd.concat([df_hd[gene], df_sle[gene]]),\n",
    "            \"Group\": [group_labels[0]] * len(df_hd) + [group_labels[1]] * len(df_sle)\n",
    "        })\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.violinplot(data=df_plot, x=\"Group\", y=\"Expression\", palette=[\"skyblue\", \"salmon\"])\n",
    "        plt.title(f\"Violin Plot of {gene} Expression\")\n",
    "        plt.xlabel(\"Group\")\n",
    "        plt.ylabel(\"Expression Level\")\n",
    "        plt.grid(True, linestyle='--', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f55aaea-1472-493f-82ba-7cb6ce9eaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_volcano_comparison(\n",
    "    de_results_list,\n",
    "    method_names,\n",
    "    fc_col='Average_Expression_Diff',\n",
    "    pval_col='AdjPValue',\n",
    "    gene_count=10150,\n",
    "    significance_level=0.05,\n",
    "    figsize=(8, 7),\n",
    "    titles=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots multiple volcano plots side-by-side for differential expression results.\n",
    "\n",
    "    Parameters:\n",
    "    - de_results_list: List of DataFrames, each with fold change and adjusted p-value columns.\n",
    "    - method_names: List of method names (used in legends and titles).\n",
    "    - fc_col: Name of the column with fold change or avg expression difference.\n",
    "    - pval_col: Name of the column with adjusted p-values.\n",
    "    - gene_count: Total number of genes (used for Bonferroni correction).\n",
    "    - significance_level: Base significance threshold (e.g., 0.05).\n",
    "    - figsize: Tuple for figure size.\n",
    "    - titles: List of titles for each subplot (optional).\n",
    "    \"\"\"\n",
    "    num_methods = len(de_results_list)\n",
    "    y_line = -np.log10(significance_level / gene_count)\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_methods, figsize=figsize, sharey=True)\n",
    "\n",
    "    if num_methods == 1:\n",
    "        axs = [axs]  # Ensure axs is always iterable\n",
    "\n",
    "    for i, (df, method) in enumerate(zip(de_results_list, method_names)):\n",
    "        ax = axs[i]\n",
    "        ax.scatter(\n",
    "            df[fc_col],\n",
    "            -np.log10(df[pval_col]),\n",
    "            alpha=0.3,\n",
    "            label=method,\n",
    "            color='steelblue'\n",
    "        )\n",
    "        ax.axhline(y=y_line, color='red', linestyle='--', linewidth=1)\n",
    "        ax.set_xlabel('Average Expression Difference')\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('-log10(Adjusted P-Value)')\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "        else:\n",
    "            ax.set_title(f\"{method} Method\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6b2e2-4f08-4d3d-a17a-f00d723fc620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_ot_sinkhorn_distances(\n",
    "    df,\n",
    "    x='Cell_Type_Prediction',\n",
    "    y='Observed_OT_Distance',\n",
    "    hue='Target_Cluster',\n",
    "    figsize=(20, 8),\n",
    "    title='OT Sinkhorn Distances per Cluster and Cell Type\\nwith Bonferroni-Adjusted p-values',\n",
    "    palette='tab20',\n",
    "    save_path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a bar chart of OT Sinkhorn distances grouped by predicted cell types and true clusters.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the data\n",
    "    - x: column name for x-axis (default: 'Cell_Type_Prediction')\n",
    "    - y: column name for y-axis (default: 'Observed_OT_Distance')\n",
    "    - hue: column name for grouping (default: 'Target_Cluster')\n",
    "    - figsize: tuple for figure size (default: (20, 8))\n",
    "    - title: plot title\n",
    "    - palette: seaborn color palette (default: 'tab20')\n",
    "    - save_path: if provided, saves the plot to the given file path\n",
    "    \"\"\"\n",
    "    # Sort by OT distance within each cluster (optional for better visuals)\n",
    "    df_sorted = (\n",
    "        df.groupby(hue, group_keys=False)\n",
    "        .apply(lambda x_: x_.sort_values(by=y, ascending=True))\n",
    "    )\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    sns.barplot(\n",
    "        data=df_sorted,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        hue=hue,\n",
    "        palette=palette\n",
    "    )\n",
    "\n",
    "    plt.legend(title='True Cell Type Annotation', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xlabel('Predicted Cell Type Annotation', fontsize=12)\n",
    "    plt.ylabel('Observed OT Sinkhorn Distance', fontsize=12)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c357c0-3ae9-48c2-9c2a-9952feed38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the assign_cell_types function as shown above\n",
    "def assign_cell_types(df, adjusted_pval_col='Adjusted_p-value', pval_threshold=0):\n",
    "    \"\"\"\n",
    "    Assigns cell types to target clusters based on the highest Observed_OT_Distance among significant associations.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the results with columns:\n",
    "        ['Cell_Type_Prediction', 'Target_Cluster', 'Observed_OT_Distance', 'p-value', 'Adjusted_p-value']\n",
    "    - adjusted_pval_col (str): Name of the column containing adjusted p-values.\n",
    "    - pval_threshold (float): Threshold to determine significance (e.g., 0 for p <= 0).\n",
    "\n",
    "    Returns:\n",
    "    - cluster_to_celltype (dict): Mapping from Target_Cluster to Cell_Type_Prediction.\n",
    "    - df_top_clusters (pd.DataFrame): DataFrame containing the top Target_Cluster for each Cell_Type_Prediction.\n",
    "    \"\"\"\n",
    "    # Step 1: Filter for significant associations\n",
    "    df_sig = df[df[adjusted_pval_col] <= pval_threshold].copy()\n",
    "\n",
    "    # Ensure 'Observed_OT_Distance' is numeric\n",
    "    df_sig['Observed_OT_Distance'] = pd.to_numeric(df_sig['Observed_OT_Distance'], errors='coerce')\n",
    "\n",
    "    # Drop rows with missing Observed_OT_Distance\n",
    "    df_sig = df_sig.dropna(subset=['Observed_OT_Distance'])\n",
    "\n",
    "    # Step 2: For each Cell_Type_Prediction, find the Target_Cluster with the highest Observed_OT_Distance\n",
    "    df_top_clusters = df_sig.loc[df_sig.groupby('Cell_Type_Prediction')['Observed_OT_Distance'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "    # Step 3: Create a mapping from Target_Cluster to Cell_Type_Prediction\n",
    "    cluster_to_celltype = pd.Series(\n",
    "        df_top_clusters.Cell_Type_Prediction.values,\n",
    "        index=df_top_clusters.Target_Cluster\n",
    "    ).to_dict()\n",
    "\n",
    "    return cluster_to_celltype, df_top_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9151e26f-7f89-40d2-8e5f-293744464c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_annotation_analysis(marker_genes, adata, target_cluster, n_pc, num_permutations=1000, lambda_reg=10):\n",
    "    \"\"\"\n",
    "    Perform OT Sinkhorn distance calculation and permutation test for a given set of marker genes.\n",
    "\n",
    "    Parameters:\n",
    "    - marker_genes: list of gene names to use for the analysis\n",
    "    - adata: AnnData object containing your single-cell data\n",
    "    - target_cluster: the cluster label (from 'louvain') to define group0\n",
    "    - num_permutations: number of permutations for the permutation test\n",
    "    - lambda_reg: regularization parameter for Sinkhorn\n",
    "\n",
    "    Returns:\n",
    "    - observed_distance: Observed OT Sinkhorn distance\n",
    "    - p_value: p-value from the permutation test\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(666)\n",
    "    \n",
    "    # Step 1: Define Group0 and Group1 based on target_cluster\n",
    "    group0 = adata[adata.obs['leiden'] == target_cluster]\n",
    "    group1 = adata[adata.obs['leiden'] != target_cluster]\n",
    "\n",
    "    # Check if both groups have enough cells\n",
    "    if group0.n_obs == 0 or group1.n_obs == 0:\n",
    "        print(f\"Insufficient cells in group0 or group1 for cluster {target_cluster}.\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # Step 2: Extract gene expression data for the marker genes\n",
    "    group0_marker = group0[:, marker_genes]\n",
    "    group1_marker = group1[:, marker_genes]\n",
    "\n",
    "    # Verify that marker genes are present\n",
    "    if group0_marker.shape[1] == 0 or group1_marker.shape[1] == 0:\n",
    "        print(f\"No marker genes found for the provided list in cluster {target_cluster}. Skipping.\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # Step 3: Convert to DataFrame for easier manipulation\n",
    "    df_expression_group0 = pd.DataFrame(group0_marker.X.toarray(), columns=group0_marker.var_names)\n",
    "    df_expression_group1 = pd.DataFrame(group1_marker.X.toarray(), columns=group1_marker.var_names)\n",
    "\n",
    "    # Step 4: Perform PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=n_pc)\n",
    "    group0_pcs = pca.fit_transform(df_expression_group0)\n",
    "    group1_pcs = pca.fit_transform(df_expression_group1)  # Use transform to maintain PCA space\n",
    "\n",
    "    # Step 5: Fit KDE for both groups in PCA space\n",
    "    try:\n",
    "        kde_group0 = stats.gaussian_kde(group0_pcs.T, bw_method='scott')\n",
    "        kde_group1 = stats.gaussian_kde(group1_pcs.T, bw_method='scott')\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(f\"KDE failed for cluster {target_cluster}. Possibly due to singular data.\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # Evaluate densities\n",
    "    density_group0 = kde_group0(group0_pcs.T)\n",
    "    density_group1 = kde_group1(group1_pcs.T)\n",
    "\n",
    "    # Step 6: Normalize densities to create probability distributions\n",
    "    mu = (density_group0 - density_group0.min()) / (density_group0.max() - density_group0.min())\n",
    "    nu = (density_group1 - density_group1.min()) / (density_group1.max() - density_group1.min())\n",
    "\n",
    "    # Step 7: Compute the cost matrix between cells in the two groups\n",
    "    X_group0 = df_expression_group0.values\n",
    "    X_group1 = df_expression_group1.values\n",
    "    cost_matrix = ot.dist(X_group0, X_group1, metric='euclidean')\n",
    "    cost_matrix_norm = (cost_matrix - cost_matrix.min()) / (cost_matrix.max() - cost_matrix.min())\n",
    "\n",
    "    # Step 8: Compute the OT Sinkhorn plan and distance\n",
    "    transport_plan = ot.sinkhorn(mu, nu, cost_matrix_norm, lambda_reg)\n",
    "    observed_distance = np.sum(transport_plan * cost_matrix_norm)\n",
    "\n",
    "    # Step 9: Permutation Test\n",
    "    combined_X = np.vstack([X_group0, X_group1])\n",
    "    n_group0 = X_group0.shape[0]\n",
    "    n_group1 = X_group1.shape[0]\n",
    "    permuted_distances = []\n",
    "\n",
    "    for i in range(num_permutations):\n",
    "        # Shuffle the combined data\n",
    "        permuted_indices = np.random.permutation(combined_X.shape[0])\n",
    "        perm_group0 = combined_X[permuted_indices[:n_group0], :]\n",
    "        perm_group1 = combined_X[permuted_indices[n_group0:], :]\n",
    "\n",
    "        # Perform PCA on permuted groups using the original PCA model\n",
    "        try:\n",
    "            perm_group0_pcs = pca.transform(perm_group0)\n",
    "            perm_group1_pcs = pca.transform(perm_group1)\n",
    "        except ValueError:\n",
    "            # In case the permutation results in invalid data for PCA\n",
    "            permuted_distances.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Fit KDE for permuted groups\n",
    "        try:\n",
    "            kde_perm_group0 = stats.gaussian_kde(perm_group0_pcs.T, bw_method='scott')\n",
    "            kde_perm_group1 = stats.gaussian_kde(perm_group1_pcs.T, bw_method='scott')\n",
    "            # Evaluate densities\n",
    "            density_perm_group0 = kde_perm_group0(perm_group0_pcs.T)\n",
    "            density_perm_group1 = kde_perm_group1(perm_group1_pcs.T)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # In case KDE fails due to singular data\n",
    "            permuted_distances.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # Normalize densities\n",
    "        mu_perm = (density_perm_group0 - density_perm_group0.min()) / (density_perm_group0.max() - density_perm_group0.min())\n",
    "        nu_perm = (density_perm_group1 - density_perm_group1.min()) / (density_perm_group1.max() - density_perm_group1.min())\n",
    "\n",
    "        # Compute cost matrix for permuted groups\n",
    "        cost_matrix_perm = ot.dist(perm_group0, perm_group1, metric='euclidean')\n",
    "        cost_matrix_perm_norm = (cost_matrix_perm - cost_matrix_perm.min()) / (cost_matrix_perm.max() - cost_matrix_perm.min())\n",
    "\n",
    "        # Compute OT Sinkhorn distance for permuted data\n",
    "        transport_plan_perm = ot.sinkhorn(mu_perm, nu_perm, cost_matrix_perm_norm, lambda_reg)\n",
    "        ot_distance_perm = np.sum(transport_plan_perm * cost_matrix_perm_norm)\n",
    "        permuted_distances.append(ot_distance_perm)\n",
    "\n",
    "    # Remove NaN values resulting from failed permutations\n",
    "    permuted_distances = np.array(permuted_distances)\n",
    "    permuted_distances = permuted_distances[~np.isnan(permuted_distances)]\n",
    "\n",
    "    # Calculate p-value\n",
    "    if len(permuted_distances) == 0:\n",
    "        p_value = np.nan\n",
    "    else:\n",
    "        p_value = np.mean(permuted_distances >= observed_distance)\n",
    "\n",
    "    return observed_distance, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff7dcf-9400-45b3-9701-2d0b00d5887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the assign_cell_types function as shown above\n",
    "def assign_cell_types(df, adjusted_pval_col='Adjusted_p-value', pval_threshold=0):\n",
    "    \"\"\"\n",
    "    Assigns cell types to target clusters based on the highest Observed_OT_Distance among significant associations.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing the results with columns:\n",
    "        ['Cell_Type_Prediction', 'Target_Cluster', 'Observed_OT_Distance', 'p-value', 'Adjusted_p-value']\n",
    "    - adjusted_pval_col (str): Name of the column containing adjusted p-values.\n",
    "    - pval_threshold (float): Threshold to determine significance (e.g., 0 for p <= 0).\n",
    "\n",
    "    Returns:\n",
    "    - cluster_to_celltype (dict): Mapping from Target_Cluster to Cell_Type_Prediction.\n",
    "    - df_top_clusters (pd.DataFrame): DataFrame containing the top Target_Cluster for each Cell_Type_Prediction.\n",
    "    \"\"\"\n",
    "    # Step 1: Filter for significant associations\n",
    "    df_sig = df[df[adjusted_pval_col] <= pval_threshold].copy()\n",
    "\n",
    "    # Ensure 'Observed_OT_Distance' is numeric\n",
    "    df_sig['Observed_OT_Distance'] = pd.to_numeric(df_sig['Observed_OT_Distance'], errors='coerce')\n",
    "\n",
    "    # Drop rows with missing Observed_OT_Distance\n",
    "    df_sig = df_sig.dropna(subset=['Observed_OT_Distance'])\n",
    "\n",
    "    # Step 2: For each Cell_Type_Prediction, find the Target_Cluster with the highest Observed_OT_Distance\n",
    "    df_top_clusters = df_sig.loc[df_sig.groupby('Cell_Type_Prediction')['Observed_OT_Distance'].idxmax()].reset_index(drop=True)\n",
    "\n",
    "    # Step 3: Create a mapping from Target_Cluster to Cell_Type_Prediction\n",
    "    cluster_to_celltype = pd.Series(\n",
    "        df_top_clusters.Cell_Type_Prediction.values,\n",
    "        index=df_top_clusters.Target_Cluster\n",
    "    ).to_dict()\n",
    "\n",
    "    return cluster_to_celltype, df_top_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5a0c3-5e19-4a40-9931-a76ebfb2a895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da09b64-7283-461c-990c-d5b86e4fc3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cccab5-97ce-48b7-9eaa-edd4fb196f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bef1cd-9791-4ca5-9053-e570965d9f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c0bac-62cc-4576-9cd5-4069f5dd1fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57a2ae-c4ed-4e56-a057-30e7fdd3ebd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd13058-8cd8-4dea-a135-5a637e9e98c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0016d-5110-45b4-ab6f-77e677370d04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
